{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "willing-theology",
   "metadata": {},
   "source": [
    "# Benchmark analysis\n",
    "\n",
    "This notebook compares the different benchmark according to the two KG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63e5181",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff7348e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import networkx as nx\n",
    "from networkx import DiGraph, MultiDiGraph, connected_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74ef14",
   "metadata": {},
   "source": [
    "# Generate graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e30b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "KG_DATA_PATH = '../data/kg/splits/'\n",
    "\n",
    "MOA_NET = os.path.join(KG_DATA_PATH, 'MoA-net')\n",
    "\n",
    "PROT_MOA_NET = os.path.join(KG_DATA_PATH, 'MoA-net-protclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cbbbcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_from_df(\n",
    "    graph_df\n",
    ") -> DiGraph:\n",
    "    \"\"\"Create fully connected graph from dataframe.\"\"\"\n",
    "    graph = DiGraph()\n",
    "\n",
    "    for sub_name, obj_name, relation in graph_df.values:\n",
    "        # Store edge in the graph\n",
    "        graph.add_edge(\n",
    "            sub_name,\n",
    "            obj_name,\n",
    "            polarity=relation,\n",
    "        )\n",
    "\n",
    "    print(f\"Report on the number of relations: {dict(Counter(graph_df.edge_type))}\")\n",
    "\n",
    "    connected_components_subgraph = [\n",
    "        component\n",
    "        for component in sorted(\n",
    "            connected_components(\n",
    "                graph.to_undirected()\n",
    "            ),\n",
    "            key=len,\n",
    "            reverse=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    final_subgraph = graph.subgraph(connected_components_subgraph[0])\n",
    "\n",
    "    return final_subgraph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2f326d2",
   "metadata": {},
   "source": [
    "For versions of MoA-net which were cut down by the automatic KG trimming feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680c5457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_from_nxobj(nx_graph_obj, node_mapping_file, edge_mapping_file):\n",
    "    graph = MultiDiGraph()\n",
    "\n",
    "    old_graph = nx.read_graphml(nx_graph_obj,\n",
    "                    node_type=int,\n",
    "                    edge_key_type=int,\n",
    "                    force_multigraph=True)\n",
    "    \n",
    "    for u, v, data in old_graph.edges(data=True):\n",
    "        graph.add_edge(\n",
    "            node_mapping_file[u],\n",
    "            node_mapping_file[v],\n",
    "            polarity=edge_mapping_file[data['type']],\n",
    "        )\n",
    "\n",
    "    connected_components_subgraph = [\n",
    "        component\n",
    "        for component in sorted(\n",
    "            connected_components(\n",
    "                graph.to_undirected()\n",
    "            ),\n",
    "            key=len,\n",
    "            reverse=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    final_subgraph = graph.subgraph(connected_components_subgraph[0])\n",
    "\n",
    "    return final_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a08b5c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on the number of relations: {'interacts': 86786, 'induces': 986, 'downregulates': 2205, 'participates': 4325, 'upregulates': 1631}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on the number of relations: {'upregulates': 1949, 'interacts': 78617, 'participates': 5027, 'downregulates': 2486, 'induces': 986}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_pairs = []\n",
    "\n",
    "for graph_type in tqdm([MOA_NET, PROT_MOA_NET]):\n",
    "\n",
    "    graph_df = pd.read_csv(\n",
    "        os.path.join(graph_type, 'kg_with_train_smpls.tsv'),\n",
    "        sep='\\t',\n",
    "        usecols=['source', 'target', 'edge_type']\n",
    "    )\n",
    "    graph = create_graph_from_df(graph_df)\n",
    "\n",
    "    gold_standard = pd.read_csv(\n",
    "        os.path.join(graph_type, 'test.tsv'),\n",
    "        sep='\\t',\n",
    "        usecols=['source', 'target']\n",
    "    )\n",
    "    gold_standard['pairs'] = gold_standard['source'] + '_' + gold_standard['target']\n",
    "    dataset_pairs.append([\n",
    "        os.path.basename(graph_type),\n",
    "        graph,\n",
    "        gold_standard['pairs'].tolist()\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f4f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the entity mapper in\n",
    "entity_mapping = json.load(open(os.path.join(MOA_NET, 'MARS/vocab/entity_vocab.json')))\n",
    "entity_mapping = {int(v): k for k, v in entity_mapping.items()}\n",
    "relation_mapping = json.load(open(os.path.join(MOA_NET, 'MARS/vocab/relation_vocab.json')))\n",
    "relation_mapping = {int(v): k for k, v in relation_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d09ad903",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_graph_from_nxobj(os.path.join(MOA_NET, 'pruned_graph.graphml'),\n",
    "                                 entity_mapping,\n",
    "                                 relation_mapping)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8849741f",
   "metadata": {},
   "source": [
    "Drop those from the test set which are no longer connected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6d32d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard = pd.read_csv(\n",
    "        os.path.join(MOA_NET, 'test.tsv'),\n",
    "        sep='\\t',\n",
    "        usecols=['source', 'target']\n",
    "    )\n",
    "\n",
    "no_path = list()\n",
    "\n",
    "for index, row in gold_standard.iterrows():\n",
    "    e1 = row['source']\n",
    "    e2 = row['target']\n",
    "\n",
    "    if e1 in graph and e2 in graph and nx.has_path(graph, e1, e2) and nx.shortest_path_length(graph, e1, e2) <= 4:\n",
    "        continue\n",
    "    else:\n",
    "        no_path.append(index)\n",
    "\n",
    "# drop those which no longer had a path:\n",
    "gold_standard.drop(index=no_path, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c11b754",
   "metadata": {},
   "source": [
    "Drop those from the validation set which are no longer connected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "650bffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = pd.read_csv(\n",
    "        os.path.join(MOA_NET, 'dev.tsv'),\n",
    "        sep='\\t',\n",
    "        usecols=['source', 'target']\n",
    "    )\n",
    "\n",
    "no_path = list()\n",
    "\n",
    "for index, row in validation_set.iterrows():\n",
    "    e1 = row['source']\n",
    "    e2 = row['target']\n",
    "\n",
    "    if e1 in graph and e2 in graph and nx.has_path(graph, e1, e2) and nx.shortest_path_length(graph, e1, e2) <= 4:\n",
    "        continue\n",
    "    else:\n",
    "        no_path.append(index)\n",
    "\n",
    "# drop those which no longer had a path:\n",
    "validation_set.drop(index=no_path, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adef59a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a395e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO write this test set to file along with validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "906860e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard['pairs'] = gold_standard['source'] + '_' + gold_standard['target']\n",
    "dataset_pairs.append([\n",
    "    os.path.basename(MOA_NET) + '-10k',\n",
    "    graph,\n",
    "    gold_standard['pairs'].tolist()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-valentine",
   "metadata": {},
   "source": [
    "# Value by change for each KG\n",
    "\n",
    "What is the change of getting our gold standard pair from all possible pair combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "falling-kernel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2181.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MoA-net': 3.381, 'MoA-net-protclass': 3.381, 'MoA-net-10k': 3.459}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_by_chance_dict = {}\n",
    "\n",
    "for graph_type, graph, gold_standard in tqdm(dataset_pairs):\n",
    "    drugs = set()\n",
    "    bps = set()\n",
    "\n",
    "    for drug_bp_pair in gold_standard:\n",
    "        drug, bp = drug_bp_pair.split('_')\n",
    "        drugs.add(drug)\n",
    "        bps.add(bp)\n",
    "\n",
    "    total = len(drugs) * len(bps)\n",
    "    prob = len(gold_standard) / total\n",
    "    val_by_chance_dict[graph_type] = round(prob * 100, 3)\n",
    "\n",
    "val_by_chance_dict "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e43c44",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baking-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_actual = {}\n",
    "kg_dfs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "subject-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def khop(\n",
    "    nodeA: str, \n",
    "    nodeB: str, \n",
    "    graph: nx.Graph, \n",
    "    total: bool\n",
    ") -> tuple:\n",
    "    \n",
    "    \"\"\"Find nodes within the distance limit \"\"\"\n",
    "    \n",
    "    khop_A = {u for u in graph.neighbors(nodeA)}\n",
    "    khop_B = {u for u in graph.neighbors(nodeB)}\n",
    "    \n",
    "    if total:\n",
    "        return list(khop_A | khop_B), khop_A, khop_B\n",
    "    else:\n",
    "        return list(khop_A & khop_B), khop_A, khop_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "senior-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_df(\n",
    "    bps, \n",
    "    drugs, \n",
    "    undirected_kg_graph, \n",
    "    di_kg_graph,\n",
    "    similarity_type,\n",
    "    similarity_name\n",
    "):\n",
    "\n",
    "    t = []\n",
    "    \n",
    "    for bp in bps:\n",
    "        \n",
    "        cn = []\n",
    "        \n",
    "        # for each disease, find the similarity score with for each drug and append to list\n",
    "        for drug in drugs:\n",
    "                        \n",
    "            shared_nodes, nodeA_neighbor, nodeB_neighbor = khop(\n",
    "                nodeA=drug,\n",
    "                nodeB=bp,\n",
    "                graph=undirected_kg_graph, \n",
    "                total=False,\n",
    "            )\n",
    "            \n",
    "            if similarity_type == 'cn':\n",
    "                similarity = len(shared_nodes)\n",
    "            \n",
    "            elif similarity_type == 'sp':\n",
    "                # try to see if path is between two nodes\n",
    "                try:\n",
    "                    similarity = len(nx.shortest_path(di_kg_graph, source=drug, target=bp))\n",
    "                except nx.NetworkXNoPath:\n",
    "                    similarity = 1000\n",
    "\n",
    "            cn.append(similarity)\n",
    "        \n",
    "        if not similarity_type == 'sp':\n",
    "            index = np.where(cn == np.amax(cn))\n",
    "        else:\n",
    "            index = np.where(cn == np.amin(cn))\n",
    "\n",
    "        # if list is full of 0's (i.e sum == 0), then there are no shared neighbors \n",
    "        if np.sum(cn) == 0:\n",
    "            continue \n",
    "        \n",
    "        for val in index:\n",
    "            for j in val:\n",
    "                t.append(\n",
    "                    {\n",
    "                        'source': list(drugs)[j], \n",
    "                        'target': bp, \n",
    "                        similarity_name: cn[j]\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return pd.DataFrame(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "892dea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(\n",
    "    gold_standard_pairs: list, \n",
    "    predicted: list,\n",
    ")-> tuple: \n",
    "    \n",
    "    total = len(predicted)\n",
    "    pos = 0\n",
    "    \n",
    "    for pair in predicted:\n",
    "        if pair in gold_standard_pairs:\n",
    "            pos += 1\n",
    "    \n",
    "    return round(((pos/total) * 100), 3), pos, total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-yemen",
   "metadata": {},
   "source": [
    "# Different benchmark methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "flying-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = {\n",
    "    'cn': 'Common Neighbors',\n",
    "    'sp': 'Shortest Path'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25be3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9abd58d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating scores for algorithms - MoA-net: 100%|██████████| 2/2 [00:02<00:00,  1.02s/it]\n",
      "Calculating scores for algorithms - MoA-net-protclass: 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]\n",
      "Calculating scores for algorithms - MoA-net-10k: 100%|██████████| 2/2 [00:01<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "for graph_type, graph, gold_standard in dataset_pairs:\n",
    "    drugs = set()\n",
    "    bps = set()\n",
    "\n",
    "    for drug_bp_pair in gold_standard:\n",
    "        drug, bp = drug_bp_pair.split('_')\n",
    "        if drug in graph.nodes():\n",
    "            drugs.add(drug)\n",
    "        \n",
    "        if bp in graph.nodes():\n",
    "            bps.add(bp)\n",
    "\n",
    "    undirected_kg_graph = graph.to_undirected()\n",
    "\n",
    "    for algo in tqdm(sim_scores, desc=f'Calculating scores for algorithms - {graph_type}'):\n",
    "        algo_name = sim_scores[algo]\n",
    "        \n",
    "        full_df = get_dict_df(\n",
    "            bps=list(bps),\n",
    "            drugs=list(drugs), \n",
    "            undirected_kg_graph=undirected_kg_graph,\n",
    "            di_kg_graph=graph,\n",
    "            similarity_type=algo,\n",
    "            similarity_name=algo_name\n",
    "        )\n",
    "\n",
    "        if full_df.empty:\n",
    "            print(f'No results for {algo_name}')\n",
    "            continue\n",
    "\n",
    "            \n",
    "        full_df['pair'] = full_df['source'] + '_' + full_df['target']\n",
    "                \n",
    "        precision, pos, total = get_precision(\n",
    "            gold_standard_pairs=gold_standard,\n",
    "            predicted=list(full_df['pair'].unique()),\n",
    "        )\n",
    "\n",
    "        score_df.append({\n",
    "            'graph_type': graph_type,\n",
    "            'algo_name': algo_name,\n",
    "            'precision': precision,\n",
    "            'val_by_chance': val_by_chance_dict[graph_type],\n",
    "            '# pairs': f'{pos}/{total}',\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf401167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>graph_type</th>\n",
       "      <th>algo_name</th>\n",
       "      <th>precision</th>\n",
       "      <th>val_by_chance</th>\n",
       "      <th># pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MoA-net</td>\n",
       "      <td>Common Neighbors</td>\n",
       "      <td>19.903</td>\n",
       "      <td>3.381</td>\n",
       "      <td>41/206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MoA-net</td>\n",
       "      <td>Shortest Path</td>\n",
       "      <td>3.546</td>\n",
       "      <td>3.381</td>\n",
       "      <td>35/987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MoA-net-protclass</td>\n",
       "      <td>Common Neighbors</td>\n",
       "      <td>19.903</td>\n",
       "      <td>3.381</td>\n",
       "      <td>41/206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MoA-net-protclass</td>\n",
       "      <td>Shortest Path</td>\n",
       "      <td>3.546</td>\n",
       "      <td>3.381</td>\n",
       "      <td>35/987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MoA-net-10k</td>\n",
       "      <td>Common Neighbors</td>\n",
       "      <td>19.903</td>\n",
       "      <td>3.459</td>\n",
       "      <td>41/206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MoA-net-10k</td>\n",
       "      <td>Shortest Path</td>\n",
       "      <td>3.593</td>\n",
       "      <td>3.459</td>\n",
       "      <td>35/974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          graph_type         algo_name  precision  val_by_chance # pairs\n",
       "0            MoA-net  Common Neighbors     19.903          3.381  41/206\n",
       "1            MoA-net     Shortest Path      3.546          3.381  35/987\n",
       "2  MoA-net-protclass  Common Neighbors     19.903          3.381  41/206\n",
       "3  MoA-net-protclass     Shortest Path      3.546          3.381  35/987\n",
       "4        MoA-net-10k  Common Neighbors     19.903          3.459  41/206\n",
       "5        MoA-net-10k     Shortest Path      3.593          3.459  35/974"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.DataFrame(score_df)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f3fc9",
   "metadata": {},
   "source": [
    "# Metrics for permuted graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8c75c84",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/kg/splits/splits/moa_net_full_permuted.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m permuted_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\n\u001b[1;32m      2\u001b[0m     os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(KG_DATA_PATH, \u001b[39m'\u001b[39;49m\u001b[39msplits\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmoa_net_full_permuted.tsv\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      3\u001b[0m     sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     usecols\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39msource\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39medge_type\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m permuted_graph \u001b[39m=\u001b[39m create_graph_from_df(permuted_df)\n\u001b[1;32m      8\u001b[0m gold_standard \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\n\u001b[1;32m      9\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(KG_DATA_PATH, \u001b[39m'\u001b[39m\u001b[39msplits\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtest.tsv\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     10\u001b[0m     sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     usecols\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/kg/splits/splits/moa_net_full_permuted.tsv'"
     ]
    }
   ],
   "source": [
    "permuted_df = pd.read_csv(\n",
    "    os.path.join(KG_DATA_PATH, 'splits', 'moa_net_full_permuted.tsv'),\n",
    "    sep='\\t',\n",
    "    usecols=['source', 'target', 'edge_type']\n",
    ")\n",
    "permuted_graph = create_graph_from_df(permuted_df)\n",
    "\n",
    "gold_standard = pd.read_csv(\n",
    "    os.path.join(KG_DATA_PATH, 'splits', 'test.tsv'),\n",
    "    sep='\\t',\n",
    "    usecols=['source', 'target']\n",
    ")\n",
    "gold_standard['pairs'] = gold_standard['source'] + '_' + gold_standard['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f4fe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating scores for algorithms - permuted:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'graph_type': 'permuted', 'algo_name': 'Common Neighbors', 'precision': 0.0, 'val_by_chance': 3.379, '# pairs': '0/106'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating scores for algorithms - permuted: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'graph_type': 'permuted', 'algo_name': 'Shortest Path', 'precision': 0.0, 'val_by_chance': 3.379, '# pairs': '0/1321'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "drugs = set()\n",
    "bps = set()\n",
    "\n",
    "for drug_bp_pair in gold_standard['pairs'].tolist():\n",
    "    drug, bp = drug_bp_pair.split('_')\n",
    "    if drug in permuted_graph.nodes():\n",
    "        drugs.add(drug)\n",
    "    \n",
    "    if bp in permuted_graph.nodes():\n",
    "        bps.add(bp)\n",
    "\n",
    "undirected_kg_permuted_graph = permuted_graph.to_undirected()\n",
    "\n",
    "for algo in tqdm(sim_scores, desc=f'Calculating scores for algorithms - permuted'):\n",
    "    algo_name = sim_scores[algo]\n",
    "    \n",
    "    full_df = get_dict_df(\n",
    "        bps=list(bps),\n",
    "        drugs=list(drugs), \n",
    "        undirected_kg_graph=undirected_kg_permuted_graph,\n",
    "        di_kg_graph=permuted_graph,\n",
    "        similarity_type=algo,\n",
    "        similarity_name=algo_name\n",
    "    )\n",
    "\n",
    "    if full_df.empty:\n",
    "        print(f'No results for {algo_name}')\n",
    "        continue\n",
    "\n",
    "        \n",
    "    full_df['pair'] = full_df['source'] + '_' + full_df['target']\n",
    "            \n",
    "    precision, pos, total = get_precision(\n",
    "        gold_standard_pairs=gold_standard,\n",
    "        predicted=list(full_df['pair'].unique()),\n",
    "    )\n",
    "\n",
    "    print({\n",
    "        'graph_type': 'permuted',\n",
    "        'algo_name': algo_name,\n",
    "        'precision': precision,\n",
    "        'val_by_chance': 3.379,\n",
    "        '# pairs': f'{pos}/{total}',\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5935544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moanet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
